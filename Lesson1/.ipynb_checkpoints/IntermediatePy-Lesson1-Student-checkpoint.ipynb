{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Python @ Calico\n",
    "\n",
    "Course instructors: [Tamas Nagy](mailto:tnagy@calicolabs.com) and [Taylor Cavazos](mailto:tcavazos@calicolabs.com)\n",
    "\n",
    "\n",
    "#### Description\n",
    "\n",
    "This course is designed to get you more comfortable with *performing common data science techniques in the Python programming language*. Python is very expressive, powerful, and popular language, especially in the data science field. You are very likely to find libraries, tutorials, and documentation for routine data science tasks in Python. The rich ecosystem will let you hit the ground running and let you quickly translate raw data into interpretable tables, statistics, and graphs. \n",
    "\n",
    "During this course, we will teach you how to perform data exploration in Python with a focus on tabular data and images. We will be using standard Python libraries that are stable, well-documented, and tested so the skills you acquire here should be helpful for many years to come. We will teach you how to tidy up your data, continuously visualize your data, and then use various statistical techniques to extract meaning from datasets.\n",
    "\n",
    "#### Objectives\n",
    "\n",
    "After finishing this course, students will be able to:\n",
    "\n",
    "1. Comfortably interact with tabular data in Python\n",
    "2. Recognize problems with datasets and correct errors \n",
    "3. Visualize datasets to derive new insight\n",
    "4. Understand and leverage common statistical approaches\n",
    "5. Extract quantitative data from images and movies\n",
    "\n",
    "#### Outline\n",
    "\n",
    "**Lesson 1:** Basic data manipulation and plotting  \n",
    "**Lesson 2:** Pre-processing, descriptive statistics, and dimensionality reduction  \n",
    "**Lesson 3:** Linear regression and interpreting statistical significance  \n",
    "**Lesson 4:** Clustering data and heatmaps  \n",
    "**Lesson 5:** Image analysis and feature extraction  \n",
    "**Lesson 6:** Temporal image data and tracking  \n",
    "\n",
    "**Optional final project:** Send us a description of a dataset you want to analyze, what question you want to answer with it, and what you would like to accomplish by the end of the course. This will help us help you!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approach for data exploration\n",
    "\n",
    "The basic approach we will taking is modeled off Hadley Wickham's [R for Data Science](https://r4ds.had.co.nz/explore-intro.html). The same principles apply whether the language is R or Python. The following figure from that book illustrates the general procedure that data scientists use when working with a dataset:\n",
    "\n",
    "![](https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is relational data?\n",
    "\n",
    "A lot of the data that we interact with is *relational* or *labeled* data where each datapoint has several associated attributes. Think of data you might interact with in Excel. A lot of scientific data can be represented in this way and this allows us to leverage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `Pandas` and `NumPy`\n",
    "\n",
    "`Pandas` and `NumPy` are two powerful Python libraries that have many convenience classes and functions. `Pandas` stands for \"panel datas\", i.e. tabular/relational data, and `NumPy` has many common numerical functions (e.g. random number generators, linear algebra, basic statistics, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` [documentation](http://pandas.pydata.org/pandas-docs/stable/user_guide/) is very thorough and I recommend giving it a read. You can also access it by running `help(function)` or `?function` in `IPython`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the `iris` dataset\n",
    "\n",
    "This is a classic dataset that is often used in introductory data science classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` function has many useful parameters that you can adjust if your dataset has nonstandard features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the `help(func)` or `?func` tools are very useful to determine what parameters and in what order you need to pass data to a function `func`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the data\n",
    "\n",
    "Our dataset is larger than what we can conveniently show on a computer screen (which is common!) so `pandas` provides some convenience functions to get a feel for the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 150 rows!\n",
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Describe everything</h3>\n",
    "\n",
    "The default behavior of `describe()` is to only print out statistics on numerical columns. Change this to all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting data\n",
    "\n",
    "In this section, we'll explore how to select specific subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a small example dataset to show indexing behavior\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": list(range(3, 11)), \n",
    "        \"char\": ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "    }\n",
    ")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column can have a different datatype, e.g. `int64`, `float`, `object`, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames have two indices for the rows and columns called `index` and `columns`, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get all the values in a column by passing its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting values\n",
    "\n",
    "We can also set values. For example, here we are adding a new column called `vals` and passing an array of correct length of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"vals\"] = [True, False, False, True, False, True, True, False] # new column with boolean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: More setting</h3>\n",
    "\n",
    "Set column `id` to the numbers between 4 and 11, inclusive. Print out the dataframe. What do you see? Are DataFrames mutable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (`loc` vs `iloc`)\n",
    "\n",
    "We can also do more advanced indexing using the `loc` and `iloc` indexers. The best way to learn the differences between them is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0:3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[0:3, \"char\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index = [5, 6, 7, 0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0:3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[0:3, \"char\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Switch to alphanumeric index and test behavior</h3>\n",
    "\n",
    "Change the index of `df2` to the values in `genes` and print out the `id`s of all genes between `NANOG` and `ACTB`, inclusive. Use both `iloc` and `loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "\n",
    "genes = [\"OCT4\", \"SOX2\", \"AQP4\", \"NANOG\", \"ATG8\", \"GAPDH\", \"ACTB\", \"MYH2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `loc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `iloc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: set subset of values</h3>\n",
    "\n",
    "Set the `id` column of `df1` equal to 10-13 for the 4th through 8th rows, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean indexing\n",
    "\n",
    "We can also provide a boolean index to only select a subset of rows (or columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"sepal_length\"] > 5 # indices where the sepal length is longer than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris[\"sepal_length\"] > 5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Boolean indexing</h3>\n",
    "\n",
    "Select all rows with `petal_length` greater than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Complex boolean indexing</h3>\n",
    "\n",
    "Select the rows with sepal lengths less than or equal to 6 **and** petal lengths greater than 2 and report the number of flowers matching this combo\n",
    "\n",
    "Hint: the `&` operator can be used to combine equalities that need to **both** be true. E.g.\n",
    "\n",
    "```\n",
    "    df[(cond) & (cond)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "`pandas` represents missing data using `np.nan`. Generally you'll want to drop rows with NaNs or replace them with realized values. Say if we select a subset of a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris = iris.copy()\n",
    "sub_iris.loc[sub_iris[\"petal_length\"] < 1.4, \"petal_length\"] = np.nan\n",
    "sub_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe() # ignores NaNs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`notna()` and `isna()` will allow you to select non-NaN or NaN values, respectively, by returning a boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris[\"petal_length\"].notna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris[\"petal_length\"].isna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `any` and `all`\n",
    "\n",
    "These two functions do exactly what they sound like. `any` returns `True` if any values along an axis are true. `all` requires all to be true to return true, otherwise it returns false.\n",
    "\n",
    "`all`:\n",
    "```\n",
    "    df[0, :] = df[0, 1] & df[0, 2] & ... \n",
    "    ...\n",
    "```\n",
    "\n",
    "`any`:\n",
    "```\n",
    "    df[0, :] = df[0, 1] | df[0, 2] | ... \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris.isna().any(1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris.isna().all(1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Set all NaNs to -1</h3>\n",
    "\n",
    "Set all NaNs in `sub_iris` to -1 and get the standard deviations for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dropna` and `fillna` to remove or replace missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_iris.fillna(-1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to plotting\n",
    "\n",
    "The primary plotting package in the Python data science ecosystem is `matplotlib`. It is an incredibly powerful and large library that has a long history and, as such, there are lots of tutorials available online that show out-of-date or non-standard approaches. To the best of our ability, we have followed best practices while plotting and also attempt to be consistent with all of our plots. \n",
    "\n",
    "### Figure vs axes vs axis\n",
    "\n",
    "`matplotlib`'s terminology can get a little confusing, but we find the following plot to be useful to remember the distinction between `figure`, `axes`, and `axis`:\n",
    "\n",
    "![](https://matplotlib.org/1.5.1/_images/fig_map.png)\n",
    "\n",
    "Lets first import `matplotlib`'s pyplot module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic scatter plot using `pyplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x=iris.sepal_length, y=iris.sepal_width, c=iris.petal_width, cmap='magma')\n",
    "plt.colorbar(label=\"petal_width\");\n",
    "plt.suptitle(\"Awesome plot\") # make sure to have a helpful titles and labels\n",
    "plt.xlabel(\"Sepal Length\") \n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic scatter using `pandas`\n",
    "\n",
    "This is still `matplotlib` in the background, but it has a different API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot.scatter(x=\"sepal_length\", y=\"sepal_width\", c=\"petal_width\", figsize=(8, 4), cmap=\"magma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms and density plots\n",
    "\n",
    "Sometimes we want to quickly identify the distribution shape. Histograms and kernel density estimates allow us to do just that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.hist(bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like petal sizes have a bimodel distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "iris[\"petal_length\"].plot.hist(ax=axes, bins=25, density=True)\n",
    "iris[\"petal_length\"].plot.kde(ax=axes)\n",
    "axes.set_xlabel(\"Petal Length\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: Selecting a certain population for plotting</h3>\n",
    "\n",
    "Select only the larger population and plot the new kernel density estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAseq dataset\n",
    "\n",
    "There are two datasets here, the first is the sample sheet (doe - design of experiment) and the second is the abundance file.  The structure of the abundance table is the first two columns are ensembl gene ID and gene symbols, and the remaining columns are samples which correspond to the sample column in the doe file. The values are ln(TPM). \n",
    "\n",
    "The RNAseq data from liver cells grown in a plate and sampled at baseline (day 0) or split into 3 groups and sampled at day 5:  BSA (control), or FFA_LPS (treatment 1) or TMC (treatment 2). Both of these treatments are design to induce the integrated stress response pathway in the liver cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"inSphero.abundance.table_edit190410.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharey=True)\n",
    "axes.scatter(df3[\"baseline_1\"], df3[\"baseline_2\"], c=df3[\"baseline_3\"])\n",
    "axes.set_xlabel(\"baseline_1\")\n",
    "axes.set_ylabel(\"baseline_2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.pearsonr(df3[\"baseline_1\"], df3[\"baseline_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharey=True)\n",
    "axes.scatter(df3[\"baseline_1\"], df3[\"DE.FFA.LPS.day5_1\"])\n",
    "axes.set_xlabel(\"baseline_1\")\n",
    "axes.set_ylabel(\"DE.FFA.LPS.day5_1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df3[\"baseline_1\"], df3[\"DE.FFA.LPS.day5_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra work: Grouping\n",
    "\n",
    "- **Splitting** the data into groups based on some criteria.\n",
    "- **Applying** a function to each group independently.\n",
    "- **Combining** the results into a data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = iris.groupby(\"species\")\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grouped` is a dict-like object that you can iterate over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in grouped:\n",
    "    print(name, \": \", group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.get_group(\"setosa\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red\">Exercise: plot groups</h3>\n",
    "\n",
    "Plot each flower type in a different color and save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
